
training:
  batch_size: 64
  epochs: 100
  learning_rate: 0.001
  optimizer: adam
  data_loader:
    num_workers: 4
    shuffle: true
  annealing_start_epoch: 5

thresholds:
  variance: 0.5
  entropy: 0.7
  sparsity: 0.3

model:
  input_dim: 784
  hidden_dims: [256, 128]
  output_dim: 10

output:
  checkpoint_dir: models/checkpoints
  final_model_path: models/final/model_v1.0_final.pth

logging:
  level: INFO
  log_file: logs/training.log
