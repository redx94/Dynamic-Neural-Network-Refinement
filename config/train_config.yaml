# config/train_config.yaml

training:
  epochs: 20
  batch_size: 64
  learning_rate: 0.001
  loss_function: CrossEntropyLoss
  log_interval: 100
  annealing_start_epoch: 5
  checkpoints:
    save_interval: 5
    checkpoint_dir: models/checkpoints/
  data_loader:
    shuffle: true
    num_workers: 4

model:
  input_dim: 784  # 28x28 MNIST images
  hidden_dims: [256, 128]
  output_dim: 10  # MNIST has 10 classes

thresholds:
  variance: 0.5
  entropy: 0.5
  sparsity: 0.5
  annealing_start_epoch: 5
  total_epochs: 20

output:
  final_model_path: models/final/model_v1.0_final.pth
  synthetic_data_path: data/synthetic/

logging:
  wandb:
    project: dynamic_nn_refinement
    entity: your_wandb_entity
